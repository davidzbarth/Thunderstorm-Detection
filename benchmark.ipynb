{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e69d2f31",
   "metadata": {},
   "source": [
    "# Benchmark of the Uploaded Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fcf67",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e15d9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from obspy import UTCDateTime\n",
    "import re\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaabc2fc",
   "metadata": {},
   "source": [
    "## Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e111b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_data = pd.read_csv(\"output.csv\") # Output of the detection algorithm, to be tested\n",
    "verification1 = pd.read_csv(\"Massachusetts/Hanscom TS.csv\") # First airport close to the station\n",
    "verification2 = pd.read_csv(\"Massachusetts/Fitchburg TS.csv\") # Second airport close to the station\n",
    "time_diff = -4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1bf76a",
   "metadata": {},
   "source": [
    "As the airports are usually $15-25$ km away from the site of the meteorological data, there are big uncertainties:\n",
    "The thunderstorm can span across the airport but not about the seismic station or vice versa.\n",
    "The storm can pass one site and get to the other site much later etc.\n",
    "\n",
    "To minimize the resulting uncertainty, it is advisable to use a second airport in the other direction from the seismic station.\n",
    "This gives a broader range for storms that may be pickup up but is still far from perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a72cd6",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d8be4",
   "metadata": {},
   "source": [
    "The data from *output.csv* needs to be converted into usable UTCDateTime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e5e66ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time_interval(interval_str):\n",
    "    \"\"\"\n",
    "    Parse a time interval string like \"2016-04-08 16:30 – 2016-08-07 08:10\"\n",
    "    Returns tuple of (start_time, end_time) as UTCDateTime objects\n",
    "    \"\"\"\n",
    "    # Check if the value is NaN or None\n",
    "    if pd.isna(interval_str) or interval_str is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Convert to string and check if empty\n",
    "    interval_str = str(interval_str).strip()\n",
    "    if interval_str == '' or interval_str == 'nan':\n",
    "        return None, None\n",
    "    \n",
    "    # Use a more specific pattern that looks for the dash between complete datetime strings\n",
    "    # Pattern: YYYY-MM-DD HH:MM [dash] YYYY-MM-DD HH:MM\n",
    "    datetime_pattern = r'(\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2})\\s*[–—−-]\\s*(\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2})'\n",
    "    \n",
    "    match = re.match(datetime_pattern, interval_str)\n",
    "    \n",
    "    if match:\n",
    "        start_str = match.group(1).strip()\n",
    "        end_str = match.group(2).strip()\n",
    "    else:\n",
    "        # Fallback: try to find two datetime patterns and assume the dash is between them\n",
    "        datetime_matches = re.findall(r'\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}', interval_str)\n",
    "        if len(datetime_matches) == 2:\n",
    "            start_str = datetime_matches[0]\n",
    "            end_str = datetime_matches[1]\n",
    "        else:\n",
    "            return None, None\n",
    "    \n",
    "    try:\n",
    "        # Parse the datetime strings\n",
    "        start_time = UTCDateTime(start_str)\n",
    "        end_time = UTCDateTime(end_str)\n",
    "        \n",
    "        return start_time, end_time\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing '{interval_str}': {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a5f23",
   "metadata": {},
   "source": [
    "The time stamps in the verification files needs to be converted to UTCDateTime too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "28ed4833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time1(i):\n",
    "    date_time = pd.to_datetime(verification1.loc[i, \"valid\"], format=\"%Y-%m-%d %H:%M\")\n",
    "    year = date_time.year\n",
    "    month = date_time.month\n",
    "    day = date_time.day\n",
    "    hour = date_time.hour\n",
    "    minute = date_time.minute\n",
    "    time= UTCDateTime(year, month, day, hour, minute)\n",
    "    time += timedelta(hours=time_diff)  # Adjust for time zone\n",
    "    return time\n",
    "\n",
    "def get_time2(i):\n",
    "    date_time = pd.to_datetime(verification2.loc[i, \"valid\"], format=\"%Y-%m-%d %H:%M\")\n",
    "    year = date_time.year\n",
    "    month = date_time.month\n",
    "    day = date_time.day\n",
    "    hour = date_time.hour\n",
    "    minute = date_time.minute\n",
    "    time= UTCDateTime(year, month, day, hour, minute)\n",
    "    time += timedelta(hours=time_diff)  # Adjust for time zone\n",
    "    return time\n",
    "\n",
    "verification1_times = np.zeros(len(verification1), dtype=UTCDateTime)\n",
    "verification2_times = np.zeros(len(verification2), dtype=UTCDateTime)\n",
    "\n",
    "for i in range(len(verification1)):\n",
    "    verification1_times[i] = get_time1(i)\n",
    "\n",
    "for i in range(len(verification2)):\n",
    "    verification2_times[i] = get_time2(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc9796",
   "metadata": {},
   "source": [
    "## Pointing out Thunderstorms from the Verification Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef33c3f9",
   "metadata": {},
   "source": [
    "The *ts_days* lists just save every day that has the weather code for thunderstorms in its data.\n",
    "*heavy_ts_days* collects multiple thunderstorm entries shortly after one another and saves them as one big thunderstorm interval.\n",
    "\n",
    "This is done for both of the airport data sets and afterwards they are merged to have one big list with all the days/time intervals for storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a8674da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_days1 = []\n",
    "for i in range(len(verification1)):\n",
    "    if \"TS\" in str(verification1.loc[i, \"wxcodes\"]) and verification1_times[i].date not in ts_days1:\n",
    "        day_start = UTCDateTime(verification1_times[i].year, verification1_times[i].month, verification1_times[i].day, 0, 0, 0)\n",
    "        day_end = day_start + timedelta(days=1)\n",
    "        ts_days1.append(verification1_times[i].date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cbccb616",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_ts_days1 = []\n",
    "heavy_ts_times1 = []\n",
    "ts_detections1 = []\n",
    "current_ts = UTCDateTime(0)\n",
    "ts_now = False\n",
    "heavy_ts_now = False\n",
    "detect_counter = 0\n",
    "start_time_current_storm = UTCDateTime(0)\n",
    "for i in range(len(verification1_times)-1):\n",
    "    if \"TS\" not in str(verification1.loc[i, \"wxcodes\"]):\n",
    "        continue\n",
    "    else:\n",
    "        day_start = UTCDateTime(verification1_times[i].year, verification1_times[i].month, verification1_times[i].day, 0, 0, 0)\n",
    "        day_end = day_start + timedelta(days=1)\n",
    "        if ts_now == False:\n",
    "            current_ts = verification1_times[i]\n",
    "            start_time_current_storm = verification1_times[i]\n",
    "            ts_now = True\n",
    "            detect_counter = 1\n",
    "        elif verification1_times[i] - current_ts > 1.5 * 3600:\n",
    "            if heavy_ts_now:\n",
    "                if start_time_current_storm.date not in heavy_ts_days1:\n",
    "                    heavy_ts_days1.append(start_time_current_storm.date)\n",
    "                heavy_ts_times1.append((start_time_current_storm, current_ts))\n",
    "                ts_detections1.append(detect_counter / float(current_ts - start_time_current_storm) * 3600)\n",
    "            current_ts = verification1_times[i]\n",
    "            start_time_current_storm = verification1_times[i]\n",
    "            ts_now = True\n",
    "            heavy_ts_now = False\n",
    "            detect_counter = 1\n",
    "        elif detect_counter == 1:\n",
    "            detect_counter += 1\n",
    "            current_ts = verification1_times[i]\n",
    "        elif detect_counter == 2:\n",
    "            detect_counter += 1\n",
    "            current_ts = verification1_times[i]\n",
    "            heavy_ts_now = True\n",
    "        else:\n",
    "            current_ts = verification1_times[i]\n",
    "            detect_counter += 1\n",
    "if \"TS\" not in str(verification1.loc[len(verification1_times)-1, \"wxcodes\"]):\n",
    "    if heavy_ts_now:\n",
    "        heavy_ts_days1.append(start_time_current_storm.date)\n",
    "        heavy_ts_times1.append((start_time_current_storm, current_ts))\n",
    "        ts_detections1.append(detect_counter/float(current_ts - start_time_current_storm) * 3600)\n",
    "\n",
    "elif \"TS\" in str(verification1.loc[len(verification1_times)-1, \"wxcodes\"]):\n",
    "    if ts_now:\n",
    "        if verification1_times[len(verification1_times)-1] - current_ts > 1.5 * 3600:\n",
    "            if heavy_ts_now:\n",
    "                heavy_ts_days1.append(start_time_current_storm.date)\n",
    "                heavy_ts_times1.append((start_time_current_storm, current_ts))\n",
    "                ts_detections1.append(detect_counter/float(current_ts - start_time_current_storm) * 3600)\n",
    "        else:\n",
    "            day_start = UTCDateTime(verification1_times[m-1].year, verification1_times[m-1].month, verification1_times[m-1].day, 0, 0, 0)\n",
    "            day_end = day_start + timedelta(days=1)\n",
    "            if heavy_ts_now:\n",
    "                current_ts = verification1_times[n-1]\n",
    "                heavy_ts_times1.append((start_time_current_storm, current_ts))\n",
    "                heavy_ts_days1.append(start_time_current_storm.date)\n",
    "                ts_detections1.append(detect_counter/(current_ts - start_time_current_storm) * 3600)\n",
    "            elif detect_counter == 2:\n",
    "                current_ts = verification1_times[n-1]\n",
    "                heavy_ts_now = True\n",
    "                heavy_ts_times1.append((start_time_current_storm, current_ts))\n",
    "                heavy_ts_days1.append(start_time_current_storm.date)\n",
    "                ts_detections1.append(detect_counter/(current_ts - start_time_current_storm) * 3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b2a87e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_days2 = []\n",
    "for i in range(len(verification2)):\n",
    "    if \"TS\" in str(verification2.loc[i, \"wxcodes\"]) and verification2_times[i].date not in ts_days2:\n",
    "        day_start = UTCDateTime(verification2_times[i].year, verification2_times[i].month, verification2_times[i].day, 0, 0, 0)\n",
    "        day_end = day_start + timedelta(days=1)\n",
    "        ts_days2.append(verification2_times[i].date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "41bee348",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_ts_days2 = []\n",
    "heavy_ts_times2 = []\n",
    "ts_detections2 = []\n",
    "current_ts = UTCDateTime(0)\n",
    "ts_now = False\n",
    "heavy_ts_now = False\n",
    "detect_counter = 0\n",
    "start_time_current_storm = UTCDateTime(0)\n",
    "for i in range(len(verification2)-1):\n",
    "    if \"TS\" not in str(verification2.loc[i, \"wxcodes\"]):\n",
    "        continue\n",
    "    else:\n",
    "        day_start = UTCDateTime(verification2_times[i].year, verification2_times[i].month, verification2_times[i].day, 0, 0, 0)\n",
    "        day_end = day_start + timedelta(days=1)\n",
    "        if ts_now == False:\n",
    "            current_ts = verification2_times[i]\n",
    "            start_time_current_storm = verification2_times[i]\n",
    "            ts_now = True\n",
    "            detect_counter = 1\n",
    "        elif verification2_times[i] - current_ts > 1.5 * 3600:\n",
    "            if heavy_ts_now:\n",
    "                if start_time_current_storm.date not in heavy_ts_days2:\n",
    "                    heavy_ts_days2.append(start_time_current_storm.date)\n",
    "                heavy_ts_times2.append((start_time_current_storm, current_ts))\n",
    "                ts_detections2.append(detect_counter / float(current_ts - start_time_current_storm) * 3600)\n",
    "            current_ts = verification2_times[i]\n",
    "            start_time_current_storm = verification2_times[i]\n",
    "            ts_now = True\n",
    "            heavy_ts_now = False\n",
    "            detect_counter = 1\n",
    "        elif detect_counter == 1:\n",
    "            detect_counter += 1\n",
    "            current_ts = verification2_times[i]\n",
    "        elif detect_counter == 2:\n",
    "            detect_counter += 1\n",
    "            current_ts = verification2_times[i]\n",
    "            heavy_ts_now = True\n",
    "        else:\n",
    "            current_ts = verification2_times[i]\n",
    "            detect_counter += 1\n",
    "if \"TS\" not in str(verification2.loc[len(verification2)-1, \"wxcodes\"]):\n",
    "    if heavy_ts_now:\n",
    "        heavy_ts_days2.append(start_time_current_storm.date)\n",
    "        heavy_ts_times2.append((start_time_current_storm, current_ts))\n",
    "        ts_detections2.append(detect_counter/float(current_ts - start_time_current_storm) * 3600)\n",
    "\n",
    "elif \"TS\" in str(verification2.loc[len(verification2)-1, \"wxcodes\"]):\n",
    "    if ts_now:\n",
    "        if verification2_times[len(verification2)-1] - current_ts > 1.5 * 3600:\n",
    "            if heavy_ts_now:\n",
    "                heavy_ts_days2.append(start_time_current_storm.date)\n",
    "                heavy_ts_times2.append((start_time_current_storm, current_ts))\n",
    "                ts_detections2.append(detect_counter/float(current_ts - start_time_current_storm) * 3600)\n",
    "        else:\n",
    "            day_start = UTCDateTime(verification2_times[len(verification2)-1].year, verification2_times[len(verification2)-1].month, verification2_times[len(verification2)-1].day, 0, 0, 0)\n",
    "            day_end = day_start + timedelta(days=1)\n",
    "            if heavy_ts_now:\n",
    "                current_ts = verification2_times[len(verification2)-1]\n",
    "                heavy_ts_times2.append((start_time_current_storm, current_ts))\n",
    "                heavy_ts_days2.append(start_time_current_storm.date)\n",
    "                ts_detections2.append(detect_counter/(current_ts - start_time_current_storm) * 3600)\n",
    "            elif detect_counter == 2:\n",
    "                current_ts = verification2_times[len(verification2)-1]\n",
    "                heavy_ts_now = True\n",
    "                heavy_ts_times2.append((start_time_current_storm, current_ts))\n",
    "                heavy_ts_days2.append(start_time_current_storm.date)\n",
    "                ts_detections2.append(detect_counter/(current_ts - start_time_current_storm) * 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "63daf8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two ts databases:\n",
    "ts_days = ts_days1.copy()\n",
    "for i in range(len(ts_days2)):\n",
    "    if ts_days2[i] not in ts_days:\n",
    "        ts_days.append(ts_days2[i])\n",
    "ts_days.sort()\n",
    "\n",
    "heavy_ts_days = heavy_ts_days1.copy()\n",
    "for i in range(len(heavy_ts_days2)):\n",
    "    if heavy_ts_days2[i] not in heavy_ts_days:\n",
    "        heavy_ts_days.append(heavy_ts_days2[i])\n",
    "heavy_ts_days.sort()\n",
    "\n",
    "#merged time intervals:\n",
    "all_intervals = heavy_ts_times1 + heavy_ts_times2\n",
    "all_intervals.sort(key=lambda x: x[0])  # Sort by start time\n",
    "\n",
    "heavy_ts_times = [all_intervals[0]]\n",
    "\n",
    "for current in all_intervals[1:]:\n",
    "    last_merged = heavy_ts_times[-1]\n",
    "    if current[0] - last_merged[1] < 3 * 3600:  # Time intervals close to each other\n",
    "        heavy_ts_times[-1] = (last_merged[0], max(last_merged[1], current[1]))\n",
    "    else:\n",
    "        heavy_ts_times.append(current)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc2584",
   "metadata": {},
   "source": [
    "Note that the merging of the time intervals still merges time intervals that are three hours apart from each other. This list doesn't have the goal to accurately display the duration of a thunderstorm but rather to give a reasonable time interval in which the storm might pass the seismic station between the two airports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68c1c18",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06996b85",
   "metadata": {},
   "source": [
    "The results are collected in the following way:\n",
    "\n",
    "If the predicted thunderstorm interval from our detection algorithm overlaps with one of the thunderstorm intervals from the verification data drawn from the airports, the predicted storm is considered a true positive.\n",
    "It is still counted as a true positive if the proposed time span contains the weather code for a thunderstorm in one of the data sets.\n",
    "\n",
    "If, at some other time during the day, there is a thunderstorm at one of the airports but the timeframe doesn't quite match the thunderstorm proposed by our algorithm, it is counted as likely true positive. \n",
    "As the airports are some distance away from the meteorological station, the thunderstorm or at least the responsible weather front might move slowly.\n",
    "\n",
    "If for a predicted thunderstorm, there is no indication of a thunderstorm during that day in either of the data sets, the storm is counted towards false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "67255933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 58\n",
      "Likely True Positives: 18\n",
      "Likely False Positives: 22\n"
     ]
    }
   ],
   "source": [
    "tp_counter = 0\n",
    "un_counter = 0\n",
    "fp_counter = 0\n",
    "index = 0\n",
    "for i in range(tested_data.shape[0]-1):\n",
    "    for j in range(tested_data.shape[1]-1):\n",
    "        tp = False\n",
    "        if parse_time_interval(tested_data.iat[i +1, j+1]) == (None, None):\n",
    "            continue\n",
    "        start, end = parse_time_interval(tested_data.iat[i +1, j+1])\n",
    "        start += timedelta(hours=-1)\n",
    "        end += timedelta(hours=1)\n",
    "        for k in range(len(heavy_ts_times)):\n",
    "            if heavy_ts_times[k][0] <= start <= heavy_ts_times[k][1] or heavy_ts_times[k][0] <= end <= heavy_ts_times[k][1]:\n",
    "                tp = True\n",
    "                break\n",
    "            elif start <= heavy_ts_times[k][0] <= end or start <= heavy_ts_times[k][1] <= end:\n",
    "                tp = True\n",
    "                break\n",
    "        if tp:\n",
    "            tp_counter += 1\n",
    "        else:\n",
    "            if start.date in ts_days:\n",
    "                for k in range(index, len(verification1)):\n",
    "                    if \"TS\" in str(verification1.loc[k, \"wxcodes\"]) and start <= verification1_times[k] <= end:\n",
    "                        tp = True\n",
    "                        index = k\n",
    "                        break\n",
    "                for k in range(k, len(verification2)):\n",
    "                    if \"TS\" in str(verification2.loc[k, \"wxcodes\"]) and start <= verification2_times[k] <= end:\n",
    "                        tp = True\n",
    "                        index = k\n",
    "                        break\n",
    "                if tp:\n",
    "                    tp_counter += 1\n",
    "                else:\n",
    "                    un_counter += 1\n",
    "            else:\n",
    "                fp_counter += 1\n",
    "\n",
    "print(f\"True Positives: {tp_counter}\")\n",
    "print(f\"Likely True Positives: {un_counter}\")\n",
    "print(f\"Likely False Positives: {fp_counter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737bd30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
